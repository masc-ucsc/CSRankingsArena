

+ Use litellm
+ Reduce costs by using prompt caching: https://docs.litellm.ai/docs/completion/prompt_caching
  + Put paper first (system), then ask questions in a go like litellm example


